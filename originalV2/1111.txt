该版本是在Original的基础上加入累积折扣奖惩来提高模型训练速度
并且使用一个α来调节价值网络和累积折扣之间的权重（即随着对弈局越来越多，价值主要是靠价值网络的输出）
* 累积折扣奖惩是考虑了：己方连子奖励、阻止对方连子奖励、被阻止连子惩罚、步数惩罚


